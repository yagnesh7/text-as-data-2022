{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import pickle\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "import contractions\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.phrases import Phrases, ENGLISH_CONNECTOR_WORDS\n",
    "\n",
    "from sklearn import (\n",
    "    linear_model,\n",
    "    feature_extraction,\n",
    "    model_selection,\n",
    "    naive_bayes,\n",
    "    metrics,\n",
    "    ensemble,\n",
    ")\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "import hypopt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(104061, 11)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/final_all_data.csv\")\n",
    "data[\"full_text\"] = data.apply(lambda x: x[\"title\"] + \" \" + x[\"selftext\"], axis=1)\n",
    "# Drop strange subreddit that is very represented in the data but has only 4.2k members.\n",
    "# data = data.loc[data[\"subreddit\"] != \"randonaut_reports\"].reset_index(drop=True)\n",
    "\n",
    "# Drop any leakage in the data from depression-related subreddits\n",
    "data = data.loc[\n",
    "    ~data[\"subreddit\"].isin(\n",
    "        [\n",
    "            \"randonaut_reports\",\n",
    "            \"depression\",\n",
    "            \"SuicideWatch\",\n",
    "            \"depression_help\",\n",
    "            \"depressed\",\n",
    "        ]\n",
    "    )\n",
    "].reset_index(drop=True)\n",
    "\n",
    "data.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depression\n",
       "0.0    14263\n",
       "1.0    15353\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"depression\")['author'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5184022150189087"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "15353/(14263+15353)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, Val, Test Sizes\n",
      "(84288,) (9366,) (10407,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    data[\"full_text\"], data[\"depression\"], test_size=0.10, random_state=42\n",
    ")\n",
    "X_train, X_val, y_train, y_val = model_selection.train_test_split(\n",
    "    X_train, y_train, test_size=0.10, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train, Val, Test Sizes\")\n",
    "print(y_train.shape, y_val.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_table = dict((ord(char), None) for char in string.punctuation + \"‘’\")\n",
    "# Pre-processing code comes from modification of Gensim's simple_tokenize to include numbers and remove punctuation\n",
    "# https://github.com/RaRe-Technologies/gensim/blob/351456b4f7d597e5a4522e71acedf785b2128ca1/gensim/utils.py#L288\n",
    "\n",
    "\n",
    "def to_unicode(text):\n",
    "    if isinstance(text, str):\n",
    "        return text.encode(\"latin\", \"ignore\").decode(\"utf-8\", \"ignore\")\n",
    "    a = str(text, \"ut8\")\n",
    "    return a.encode(\"latin\", \"ignore\").decode(\"utf-8\", \"ignore\")\n",
    "\n",
    "def preprocess(text):\n",
    "    text = to_unicode(text)\n",
    "    if lowercase:\n",
    "        text = text.lower()\n",
    "\n",
    "    if deaccent:\n",
    "        text = unicodedata.normalize(\"NFD\", text)\n",
    "        text = \"\".join(ch for ch in text if unicodedata.category(ch) != \"Mn\")\n",
    "        text = unicodedata.normalize(\"NFC\", text)\n",
    "\n",
    "    # Remove /r/depression\n",
    "    if remove_leaks:\n",
    "        text = re.sub(r\"\\/?r\\/?depression\", \"\", text)\n",
    "    # Remove URL\n",
    "    if remove_urls:\n",
    "        text = re.sub(r\"https?:\\/\\/\\S+\", \"\", text)\n",
    "\n",
    "    if remove_reddit_chars:\n",
    "        text = re.sub(r\"\\/r\\/|\\/u\\/\", \"\", text)\n",
    "\n",
    "    if expand_contractions:\n",
    "        text = contractions.fix(text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    if remove_punctuation:\n",
    "        text = text.replace(\"-\", \" \")\n",
    "        text = text.translate(translate_table)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    if remove_numbers:\n",
    "        text = [w for w in text if not w.isdigit()]\n",
    "\n",
    "    return [token for token in text if min_len <= len(token) and max_len >= len(token)]\n",
    "\n",
    "\n",
    "min_len = 1\n",
    "max_len = 15\n",
    "\n",
    "lowercase = True\n",
    "deaccent = True\n",
    "remove_leaks = True\n",
    "remove_urls = True\n",
    "remove_reddit_chars = True\n",
    "expand_contractions = True\n",
    "remove_punctuation = True\n",
    "remove_numbers = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clean = list(map(preprocess, X_train))\n",
    "X_val_clean = list(map(preprocess, X_val))\n",
    "X_test_clean = list(map(preprocess, X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"positive-words.txt\", \"r\") as file:\n",
    "    positives = file.readlines()\n",
    "\n",
    "positives = [w.replace(\"\\n\",\"\") for w in positives]\n",
    "\n",
    "with open(\"negative-words.txt\", \"r\") as file:\n",
    "    negatives = file.readlines()\n",
    "\n",
    "negatives = [w.replace(\"\\n\",\"\") for w in negatives]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yagne\\anaconda3\\envs\\common\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_clean = pd.DataFrame(data = {\"y\": y_train,\n",
    "    \"real_index\": X_train.index,\n",
    "    \"cleaned_text\": X_train_clean\n",
    "})\n",
    "train_clean[\"post_length\"] = train_clean[\"cleaned_text\"].apply(lambda x: len(x))\n",
    "\n",
    "def dummy(doc):\n",
    "    return doc\n",
    "\n",
    "wc_cv = feature_extraction.text.CountVectorizer(\n",
    "    binary=False,\n",
    "    tokenizer=dummy,\n",
    "    preprocessor=dummy,\n",
    ")\n",
    "\n",
    "wc_cv = wc_cv.fit(train_clean[\"cleaned_text\"])\n",
    "train_wc = wc_cv.transform(train_clean[\"cleaned_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_lookup(mat, cv, references):\n",
    "    holder = np.zeros(shape=(mat.shape[0],1))\n",
    "\n",
    "    for r in references:\n",
    "      try:\n",
    "        holder = holder + mat[:,cv.vocabulary_[r]].toarray()\n",
    "      except:\n",
    "        continue\n",
    "    return holder\n",
    "train_clean[\"first_person_singular\"] = cv_lookup(train_wc, wc_cv, [\"i\",\"me\",\"mine\", \"myself\"])\n",
    "train_clean[\"first_person_plural\"] = cv_lookup(train_wc, wc_cv, [\"we\",\"us\",\"ours\", \"our\", \"ourselves\"])\n",
    "train_clean[\"positive_words\"] = cv_lookup(train_wc, wc_cv,positives)\n",
    "train_clean[\"negative_words\"] = cv_lookup(train_wc, wc_cv,negatives)\n",
    "\n",
    "train_clean[\"fs_ratio\"] = train_clean[\"first_person_singular\"]/train_clean[\"post_length\"]\n",
    "train_clean[\"fp_ratio\"] = train_clean[\"first_person_plural\"]/train_clean[\"post_length\"]\n",
    "\n",
    "train_clean[\"pos_ratio\"] = train_clean[\"positive_words\"]/train_clean[\"post_length\"]\n",
    "train_clean[\"neg_ratio\"] = train_clean[\"negative_words\"]/train_clean[\"post_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_index</th>\n",
       "      <th>post_length</th>\n",
       "      <th>first_person_singular</th>\n",
       "      <th>first_person_plural</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>fs_ratio</th>\n",
       "      <th>fp_ratio</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>neg_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>76074.578217</td>\n",
       "      <td>128.712200</td>\n",
       "      <td>7.016492</td>\n",
       "      <td>0.655950</td>\n",
       "      <td>4.178050</td>\n",
       "      <td>4.049828</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.033055</td>\n",
       "      <td>0.030092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>23996.356488</td>\n",
       "      <td>133.078223</td>\n",
       "      <td>9.255127</td>\n",
       "      <td>0.576729</td>\n",
       "      <td>4.329331</td>\n",
       "      <td>5.024168</td>\n",
       "      <td>0.067874</td>\n",
       "      <td>0.003783</td>\n",
       "      <td>0.033023</td>\n",
       "      <td>0.036816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       real_index  post_length  first_person_singular  first_person_plural  \\\n",
       "y                                                                            \n",
       "0.0  76074.578217   128.712200               7.016492             0.655950   \n",
       "1.0  23996.356488   133.078223               9.255127             0.576729   \n",
       "\n",
       "     positive_words  negative_words  fs_ratio  fp_ratio  pos_ratio  neg_ratio  \n",
       "y                                                                              \n",
       "0.0        4.178050        4.049828  0.052863  0.004766   0.033055   0.030092  \n",
       "1.0        4.329331        5.024168  0.067874  0.003783   0.033023   0.036816  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.groupby(\"y\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real_index</th>\n",
       "      <th>post_length</th>\n",
       "      <th>first_person_singular</th>\n",
       "      <th>first_person_plural</th>\n",
       "      <th>positive_words</th>\n",
       "      <th>negative_words</th>\n",
       "      <th>fs_ratio</th>\n",
       "      <th>fp_ratio</th>\n",
       "      <th>pos_ratio</th>\n",
       "      <th>neg_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>16162.943020</td>\n",
       "      <td>87.032999</td>\n",
       "      <td>7.545316</td>\n",
       "      <td>1.688515</td>\n",
       "      <td>4.008631</td>\n",
       "      <td>4.541178</td>\n",
       "      <td>0.037651</td>\n",
       "      <td>0.011822</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>0.027240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>13842.784219</td>\n",
       "      <td>90.277316</td>\n",
       "      <td>8.509657</td>\n",
       "      <td>1.584321</td>\n",
       "      <td>4.064876</td>\n",
       "      <td>5.282905</td>\n",
       "      <td>0.037193</td>\n",
       "      <td>0.009978</td>\n",
       "      <td>0.023824</td>\n",
       "      <td>0.029765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       real_index  post_length  first_person_singular  first_person_plural  \\\n",
       "y                                                                            \n",
       "0.0  16162.943020    87.032999               7.545316             1.688515   \n",
       "1.0  13842.784219    90.277316               8.509657             1.584321   \n",
       "\n",
       "     positive_words  negative_words  fs_ratio  fp_ratio  pos_ratio  neg_ratio  \n",
       "y                                                                              \n",
       "0.0        4.008631        4.541178  0.037651  0.011822   0.024961   0.027240  \n",
       "1.0        4.064876        5.282905  0.037193  0.009978   0.023824   0.029765  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean.groupby(\"y\").std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20.63"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(((0.003783-0.004766)/0.004766)*100,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_clean = pd.DataFrame(data = {\"real_index\": X_val.index, \"cleaned_text\": X_val_clean})\n",
    "val_clean[\"post_length\"] = val_clean[\"cleaned_text\"].apply(lambda x: len(x))\n",
    "\n",
    "val_wc = wc_cv.transform(val_clean[\"cleaned_text\"])\n",
    "\n",
    "val_clean[\"first_person_singular\"] = cv_lookup(val_wc, wc_cv, [\"i\",\"me\",\"mine\", \"myself\"])\n",
    "val_clean[\"first_person_plural\"] = cv_lookup(val_wc, wc_cv, [\"we\",\"us\",\"ours\",\"ourselves\"])\n",
    "val_clean[\"positive_words\"] = cv_lookup(val_wc, wc_cv,positives)\n",
    "val_clean[\"negative_words\"] = cv_lookup(val_wc, wc_cv,negatives)\n",
    "\n",
    "val_clean[\"fs_ratio\"] = val_clean[\"first_person_singular\"]/val_clean[\"post_length\"]\n",
    "val_clean[\"fp_ratio\"] = val_clean[\"first_person_plural\"]/val_clean[\"post_length\"]\n",
    "val_clean[\"pos_ratio\"] = val_clean[\"positive_words\"]/val_clean[\"post_length\"]\n",
    "val_clean[\"neg_ratio\"] = val_clean[\"negative_words\"]/val_clean[\"post_length\"]\n",
    "\n",
    "test_clean = pd.DataFrame(data = {\"real_index\": X_test.index, \"cleaned_text\": X_test_clean})\n",
    "test_clean[\"post_length\"] = test_clean[\"cleaned_text\"].apply(lambda x: len(x))\n",
    "test_wc = wc_cv.transform(test_clean[\"cleaned_text\"])\n",
    "\n",
    "\n",
    "test_clean[\"first_person_singular\"] = cv_lookup(test_wc, wc_cv, [\"i\",\"me\",\"mine\", \"myself\"])\n",
    "test_clean[\"first_person_plural\"] = cv_lookup(test_wc, wc_cv, [\"we\",\"us\",\"ours\",\"ourselves\"])\n",
    "test_clean[\"positive_words\"] = cv_lookup(test_wc, wc_cv,positives)\n",
    "test_clean[\"negative_words\"] = cv_lookup(test_wc, wc_cv,negatives)\n",
    "\n",
    "test_clean[\"fs_ratio\"] = test_clean[\"first_person_singular\"]/test_clean[\"post_length\"]\n",
    "test_clean[\"fp_ratio\"] = test_clean[\"first_person_plural\"]/test_clean[\"post_length\"]\n",
    "test_clean[\"pos_ratio\"] = test_clean[\"positive_words\"]/test_clean[\"post_length\"]\n",
    "test_clean[\"neg_ratio\"] = test_clean[\"negative_words\"]/test_clean[\"post_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = pd.concat([train_clean.drop(\"y\", axis=1),val_clean,test_clean])\n",
    "cleaned_df = cleaned_df.sort_values(\"real_index\").reset_index(drop=True)\n",
    "cleaned_df[\"cleaned_text\"] = cleaned_df[\"cleaned_text\"].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data, cleaned_df[[\"cleaned_text\", 'first_person_singular',\n",
    "       'first_person_plural', 'positive_words', 'negative_words', 'fs_ratio',\n",
    "       'fp_ratio', 'pos_ratio', 'neg_ratio']]],axis =1).to_csv(\"data/word_count.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88bd46a81829761a1f8655c40b7d07d46ff042d1c1b2d447b6a3515fda4bcd96"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('common')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
